{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28) y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py # pip3 install h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the mnist pre-shuffled train data and test data: RUNTERGUCKEN\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The cell above contains the usual \"magic\": it imports certain libraries that allow to use OS functionalities, plotting and most importantly the TensorFlow library.\n",
    "\n",
    "It also downloads the dataset and we look at the \"shape\", that is: how many samples, how are they stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1214d8198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 12\n",
    "plt.imshow(x_train[index])\n",
    "print(\"That's a \" + str(y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  12,  99,  91, 142, 155, 246, 182, 155, 155, 155,\n",
       "        155, 131,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 138, 254, 254, 254, 254, 254, 254, 254, 254, 254,\n",
       "        254, 254, 252, 210, 122,  33,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 220, 254, 254, 254, 235, 189, 189, 189, 189, 150,\n",
       "        189, 205, 254, 254, 254,  75,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  35,  74,  35,  35,  25,   0,   0,   0,   0,   0,\n",
       "          0,  13, 224, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  90, 254, 254, 247,  53,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "        152, 246, 254, 254,  49,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 158,\n",
       "        254, 254, 249, 103,   8,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 251, 254,\n",
       "        254, 254, 248,  74,   5,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 254, 254,\n",
       "        254, 254, 254, 254, 202, 125,  45,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 181, 234,\n",
       "        254, 254, 254, 254, 254, 254, 252, 140,  22,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  30,\n",
       "         50,  73, 155, 253, 254, 254, 254, 254, 191,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  91, 200, 254, 254, 254, 254, 118,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   4, 192, 254, 254, 254, 154,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 141, 254, 254, 254, 116,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  25, 126,  86,   0,   0,\n",
       "          0,   0,   0,   0,   3, 188, 254, 254, 250,  61,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  24, 209, 254,  15,   0,   0,\n",
       "          0,   0,   0,  23, 137, 254, 254, 254, 209,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 168, 254, 254,  48,   9,   0,\n",
       "          0,   9, 127, 241, 254, 254, 255, 242,  63,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 101, 254, 254, 254, 205, 190,\n",
       "        190, 205, 254, 254, 254, 254, 242,  67,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  33, 166, 254, 254, 254, 254,\n",
       "        254, 254, 254, 254, 250, 138,  55,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   7,  88, 154, 116, 194,\n",
       "        194, 154, 154,  88,  49,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to reshape the data. First, we take some more picture and put them into a special validation set which is not used during training.\n",
    "\n",
    "Then we have to change the form of the data a little bit, but that's just for technical reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the magic: we build the neural network. It consists of a few convolution layers with maxpool and a couple of dense (aka \"normal\") layers in between. That's a big network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 7, 32)          1056      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               73984     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 90,282\n",
      "Trainable params: 90,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly set up what kind of error (\"loss\") function we want and what specific optimization we use. ADAM is similar to our gradient descent from before, but it's adaptive! So it changes its stride in a clever way according to the way the error changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also pretty nifty: we use the training and validation data from before to train our model. Caution: each epoch takes about 1.5 minutes! But then we save the best model measured from the accuracy on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "55000/55000 [==============================] - 179s 3ms/step - loss: 14.5565 - acc: 0.0966 - val_loss: 14.3935 - val_acc: 0.1070\n",
      "Epoch 2/15\n",
      "55000/55000 [==============================] - 194s 4ms/step - loss: 14.5628 - acc: 0.0965 - val_loss: 14.3935 - val_acc: 0.1070\n",
      "Epoch 3/15\n",
      "55000/55000 [==============================] - 188s 3ms/step - loss: 14.5628 - acc: 0.0965 - val_loss: 14.3935 - val_acc: 0.1070\n",
      "Epoch 4/15\n",
      "47900/55000 [=========================>....] - ETA: 24s - loss: 14.5625 - acc: 0.0965"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-641f76446d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m          callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     updated = session.run(\n\u001b[0;32m-> 2824\u001b[0;31m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2825\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 0, save_best_only=True)\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=2,\n",
    "         epochs=15,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load that best model into memory.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And validate it against the test data (test isn't validation)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random samples and check if the model predicted them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=25, replace=False)):\n",
    "    ax = figure.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
    "    \n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    \n",
    "    ax.set_title(\"{} ({})\".format(predict_index, true_index),\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
